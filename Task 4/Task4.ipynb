{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tempfile import mkdtemp\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor, StackingClassifier, StackingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA, KernelPCA, FastICA\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.multioutput import RegressorChain, ClassifierChain\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel, f_classif\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('trainset', 'task_4_train_generic.csv'))\n",
    "pd.set_option('display.max_columns', None)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, data_components=[], target_components=[]):\n",
    "    groups = pd.Series(df[\"segment_id\"],  name='groups') #pd.Series(df[\"pianist_id\"]*100 + df[\"segment_id\"], name='groups')\n",
    "    X = pd.DataFrame(index=df.index)\n",
    "    y = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for component in data_components:\n",
    "        if component == \"emotions\":\n",
    "            X = pd.concat([X, df.iloc[:, 175 : 188]], axis=1)\n",
    "        elif component == \"emotions_binary\":\n",
    "            X = pd.concat([X, df.iloc[:, 188:]], axis=1)\n",
    "        elif component == \"tech_features\":\n",
    "            X = pd.concat([X, df.iloc[:, 3:172]], axis=1)\n",
    "        elif component == \"valence_arousal\":\n",
    "            X = pd.concat([X, df[['valence', 'arousal']]], axis=1)\n",
    "\n",
    "    for component in target_components:\n",
    "        if component in df.columns:\n",
    "            y = pd.concat([y, df[component]], axis=1)\n",
    "        elif component == 'valence_arousal':\n",
    "            y = pd.concat([y, df[['valence', 'arousal']]], axis=1)\n",
    "        elif component == 'emotions':\n",
    "            y = pd.concat([y, df.iloc[:, 175 : 189]], axis=1)\n",
    "        elif component == 'emotions_binary':\n",
    "            y = pd.concat([y, df.iloc[:, 189:]], axis=1)\n",
    "        elif component == 'group_idx':\n",
    "            y = pd.concat([y, groups], axis=1)\n",
    "\n",
    "    return (X, y, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence   arousal  groups\n",
       "0    -0.363636  2.818182       0\n",
       "1    -0.363636  2.818182       0\n",
       "2    -0.363636  2.818182       0\n",
       "3    -0.363636  2.818182       0\n",
       "4    -0.363636  2.818182       0\n",
       "...        ...       ...     ...\n",
       "1922  0.363636  2.000000      22\n",
       "1923  0.363636  2.000000      22\n",
       "1924  0.363636  2.000000      22\n",
       "1925  0.363636  2.000000      22\n",
       "1926  0.363636  2.000000      22\n",
       "\n",
       "[1927 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, groups = load_data(df, data_components=['emotions', 'tech_features', 'valence_arousal'], target_components=['valence_arousal', 'group_idx'])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Scoring/Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAIN_MATRIX = np.array([\n",
    "    [5, -5, -5, 2],\n",
    "    [-5, 10, 2, -5],\n",
    "    [-5, 2, 10, -5],\n",
    "    [2, -5, -2, 5]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.363636</td>\n",
       "      <td>2.818182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1927 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       valence   arousal  groups\n",
       "0    -0.363636  2.818182       0\n",
       "1    -0.363636  2.818182       0\n",
       "2    -0.363636  2.818182       0\n",
       "3    -0.363636  2.818182       0\n",
       "4    -0.363636  2.818182       0\n",
       "...        ...       ...     ...\n",
       "1922  0.363636  2.000000      22\n",
       "1923  0.363636  2.000000      22\n",
       "1924  0.363636  2.000000      22\n",
       "1925  0.363636  2.000000      22\n",
       "1926  0.363636  2.000000      22\n",
       "\n",
       "[1927 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, _  = load_data(df, data_components=['tech_features'], target_components=['valence_arousal', 'group_idx'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_error_grouped(y_true, y_hat):\n",
    "\n",
    "    y_hat[:,-1] = y_true[:,-1].copy()\n",
    "\n",
    "    means_grouped_y_hat = np.empty((len(np.unique(y_true[:,-1])), len(y_true[0]))) #means of groups with shape n_groups x n_predicted_features\n",
    "    means_grouped_y_true = np.empty((len(np.unique(y_true[:,-1])), len(y_true[0]))) # container for grouped y_true data\n",
    "    cost = 0\n",
    "    N = len(means_grouped_y_hat)\n",
    "\n",
    "    cost_matrix = np.array([\n",
    "    [5, -5, -5, 2],\n",
    "    [-5, 10, 2, -5],\n",
    "    [-5, 2, 10, -5],\n",
    "    [2, -5, -2, 5]\n",
    "    ])\n",
    "\n",
    "\n",
    "    for i, id in enumerate(np.unique(y_true[:,-1])): #unique group IDs\n",
    "        current_group_indices = np.where(y_hat[:,-1] == id)\n",
    "        means_grouped_y_true[i] = y_true[current_group_indices].mean(axis=0)\n",
    "        means_grouped_y_hat[i] = y_hat[current_group_indices].mean(axis=0)\n",
    "\n",
    "\n",
    "    for y, prediction in zip(means_grouped_y_true, means_grouped_y_hat):\n",
    "        prediction_quadrant = v_a_to_quadrant_skewed(prediction[0], prediction[1])\n",
    "        y_quadrant = v_a_to_quadrant(y[0], y[1])\n",
    "\n",
    "        cost += cost_matrix[y_quadrant-1][prediction_quadrant-1]\n",
    "\n",
    "\n",
    "\n",
    "    return cost/N\n",
    "\n",
    "custom_grouped_scorer = make_scorer(custom_error_grouped, greater_is_better=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor(model_params, data_components=['tech_features'], target_components=['valence_arousal'], top_X=[10], scalers=[], regressors=[], feature_selectors=[], embedders=[], \n",
    "                    n_jobs=-1, cv=5, scoring='neg_mean_squared_error', memory=None):  #model params must be array of objects with same length as classifiers\n",
    "\n",
    "    X, y, groups = load_data(df, data_components=data_components, target_components=target_components)\n",
    "    \n",
    "    cv = GroupShuffleSplit(n_splits=cv, random_state=42)\n",
    "\n",
    "    current_best_score_regr = -1000\n",
    "    current_best_regressor = None\n",
    "    grid_results = []\n",
    "\n",
    "    for i, regr_model_class in enumerate(regressors):\n",
    "        print(f'Regressor model class: {regr_model_class}')\n",
    "        for feat_model_class in feature_selectors:\n",
    "            print(f'Feature selector model class: {feat_model_class}')\n",
    "            for emb_model_class in embedders:\n",
    "                print(f'Embedding model class: {emb_model_class}')\n",
    "                for scaler in scalers:\n",
    "                    for num in top_X:\n",
    "\n",
    "                        pipe = Pipeline(steps=[\n",
    "                            ('scaler', scaler),\n",
    "                            ('embedder', emb_model_class),\n",
    "                            ('feature_selector', 'passthrough' if feat_model_class == 'passthrough' else SelectFromModel(feat_model_class, max_features=num)),\n",
    "                            ('estimator', RegressorChain(regr_model_class))\n",
    "                        ], verbose=True, memory=memory)\n",
    "\n",
    "                        print('Possbile params: ')\n",
    "                        print(pipe.get_params().keys())\n",
    "                        gs=GridSearchCV(pipe, model_params[i], n_jobs=n_jobs, cv=cv, scoring=scoring, verbose=10, error_score=\"raise\")\n",
    "                        gs.fit(X, y.to_numpy(), groups=groups)\n",
    "                        result = gs.cv_results_\n",
    "                        if gs.best_score_ > current_best_score_regr:\n",
    "                            current_best_regressor = gs.best_estimator_\n",
    "                            current_best_score_regr = gs.best_score_\n",
    "                            dump(current_best_regressor, os.path.join(f'best_{str(regr_model_class)[:5]}.joblib') )\n",
    "                        grid_results.append(pd.DataFrame.from_dict(result))\n",
    "                        print(f'Num max_features: {num}')\n",
    "                        print(gs.best_score_)\n",
    "                        print('_______________')\n",
    "    return (current_best_regressor, gs.best_params_, current_best_score_regr, grid_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressor model class: KNeighborsRegressor()\n",
      "Feature selector model class: passthrough\n",
      "Embedding model class: passthrough\n",
      "Possbile params: \n",
      "dict_keys(['memory', 'steps', 'verbose', 'scaler', 'embedder', 'feature_selector', 'estimator', 'scaler__copy', 'scaler__ignore_implicit_zeros', 'scaler__n_quantiles', 'scaler__output_distribution', 'scaler__random_state', 'scaler__subsample', 'estimator__base_estimator__algorithm', 'estimator__base_estimator__leaf_size', 'estimator__base_estimator__metric', 'estimator__base_estimator__metric_params', 'estimator__base_estimator__n_jobs', 'estimator__base_estimator__n_neighbors', 'estimator__base_estimator__p', 'estimator__base_estimator__weights', 'estimator__base_estimator', 'estimator__cv', 'estimator__order', 'estimator__random_state'])\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Pipeline] ............ (step 1 of 4) Processing scaler, total=   0.9s\n",
      "[Pipeline] .......... (step 2 of 4) Processing embedder, total=   0.0s\n",
      "[Pipeline] .. (step 3 of 4) Processing feature_selector, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 4) Processing estimator, total=   0.0s\n",
      "Num max_features: 150\n",
      "5.24\n",
      "_______________\n"
     ]
    }
   ],
   "source": [
    "scalers = [\n",
    "    # 'passthrough',\n",
    "    # StandardScaler(),\n",
    "    QuantileTransformer(),\n",
    "    # MinMaxScaler(),\n",
    "    # MaxAbsScaler()\n",
    "]\n",
    "\n",
    "regressors = [    \n",
    "    # RandomForestRegressor(),\n",
    "    KNeighborsRegressor(),\n",
    "    # SVR(),\n",
    "    # XGBRegressor(),\n",
    "    # AdaBoostRegressor(), \n",
    "#     StackingRegressor(estimators=[\n",
    "#         ('Ada', AdaBoostRegressor()), \n",
    "#         ('RF', RandomForestRegressor()),\n",
    "#         ('KNN', KNeighborsRegressor())\n",
    "#     ])\n",
    "]\n",
    "\n",
    "feature_selectors = [\n",
    "    'passthrough',\n",
    "    # RandomForestRegressor(n_estimators=50),\n",
    "]\n",
    "\n",
    "embedders = [\n",
    "    'passthrough',\n",
    "    # PCA(),\n",
    "    # KernelPCA()\n",
    "]\n",
    "\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "model_params = [{} for model in regressors]\n",
    "\n",
    "#Random Forest\n",
    "# model_params[0] = {\n",
    "#     'estimator__base_estimator__n_estimators': [10, 50, 200, 500, 1000],\n",
    "#     'estimator__base_estimator__max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'estimator__base_estimator__max_depth': [4,6,8],\n",
    "#     'feature_selector__estimator__n_estimators': [50]\n",
    "    \n",
    "# }\n",
    "\n",
    "#kNN\n",
    "model_params[0] = {\n",
    "    'estimator__base_estimator__n_neighbors': [2, 5, 10, 20, 25, 30],\n",
    "    'estimator__base_estimator__weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "#Support Vector Machine\n",
    "# model_params[0] = {\n",
    "    # 'estimator__base_estimator__kernel': ['rbf'],\n",
    "    # 'estimator__base_estimator__gamma': [1, 0.1, 0.01, 'scale', 'auto'],\n",
    "    # 'estimator__base_estimator__C': [1, 10, 100],\n",
    "    # 'feature_selector__estimator__n_estimators': [10, 25, 100]\n",
    "# }\n",
    "\n",
    "#XGBoost\n",
    "# model_params[0] = {\n",
    "#     'estimator__base_estimator__objective': ['reg:squarederror'],\n",
    "#     'estimator__base_estimator__learning_rate': [0.2],\n",
    "#     'estimator__base_estimator__n_estimators': [100],\n",
    "#     'estimator__base_estimator__max_depth': [4],\n",
    "#     'estimator__base_estimator__min_child_weight': [2],\n",
    "#     'estimator__base_estimator__gamma': [0.1],\n",
    "#     'estimator__base_estimator__subsample': [0.9],\n",
    "#     'estimator__base_estimator__colsample_bytree': [0.8],\n",
    "# }\n",
    "\n",
    "#AdaBoost\n",
    "# model_params[0] = {\n",
    "#     'estimator__base_estimator__base_estimator': [\n",
    "#         KNeighborsRegressor(n_neighbors=10),\n",
    "#         KNeighborsRegressor(n_neighbors=5)\n",
    "#     ],\n",
    "#     'estimator__base_estimator__n_estimators':[25, 50, 100],\n",
    "#     'estimator__base_estimator__learning_rate':[0.1],\n",
    "#     # 'estimator__base_estimator__learning_rate':[0.01, 0.05, 0.1],\n",
    "#     'estimator__base_estimator__loss': ['linear', 'square'],\n",
    "# }\n",
    "\n",
    "top_X = [150]\n",
    "\n",
    "best_regressor, best_params, best_score, grid_result = train_regressor(model_params,\n",
    "                                data_components=['tech_features'], \n",
    "                                # target_components=['valence_arousal', 'group_idx'], \n",
    "                                target_components=['valence_arousal', 'group_idx'], \n",
    "                                regressors=regressors, \n",
    "                                feature_selectors=feature_selectors, \n",
    "                                embedders=embedders,\n",
    "                                scalers=scalers,\n",
    "                                top_X=top_X,\n",
    "                                memory=cachedir,\n",
    "                                n_jobs=16,\n",
    "                                cv=5,\n",
    "                                scoring=custom_grouped_scorer#'neg_mean_squared_error'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__base_estimator__n_neighbors': 20,\n",
       " 'estimator__base_estimator__weights': 'uniform'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_a_to_quadrant(valence, arousal):\n",
    "    if arousal < 3:\n",
    "        if valence < 0:\n",
    "            return 3 # sad\n",
    "        return 4 # relaxed\n",
    "    if valence < 0:\n",
    "        return 2 # angry\n",
    "    return 1 # happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_a_to_quadrant_skewed(valence, arousal):\n",
    "    if arousal < 3.2:\n",
    "        if valence < 0.4:\n",
    "            return 3 # sad\n",
    "        return 4 # relaxed\n",
    "    if valence < 0.4:\n",
    "        return 2 # angry\n",
    "    return 1 # happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d06b7f189755ffe906b3c03a1b4897b441226e30fd3256924a77eb54768b435"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
